{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projet algo mémoire.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KangooCode/TweetsScraper/blob/main/projet_algo_m%C3%A9moire.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!apt-get -q install python3.8"
      ],
      "metadata": {
        "id": "YZdQkWVcpp7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -q snscrape\n",
        "!pip3 install -q pandas"
      ],
      "metadata": {
        "id": "5szdatANmnn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udqyLeHvFkAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343bd3cc-2a64-4339-cef4-9eadf21bc7a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Date, Username, Content]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "#Scraper de tweets\n",
        "\n",
        "from snscrape.modules import twitter as sntwitter\n",
        "import pandas as pd\n",
        "\n",
        "queries = ['fuck', 'sex', 'rape']\n",
        "tweets = []\n",
        "limit = 500\n",
        "\n",
        "for n, k in enumerate(queries):\n",
        "  for i,tweet in enumerate(sntwitter.TwitterSearchScraper(queries[n]).get_items()):\n",
        "    if i > limit:\n",
        "      break\n",
        "    tweets.append([tweet.date, tweet.username, tweet.content])\n",
        "\n",
        "df = pd.DataFrame(tweets, columns=['Date', 'Username', 'Content'])\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Algo modération\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Search_keywords = df.loc[df['Content'].str.contains(\"sex|rape|sexual|sexy|hot\", case=False)]\n",
        "\n",
        "df.loc[(df['Content'] == 'sex')|(df['Content'] == 'rape')|(df['Content'] == 'sexual')|(df['Content'] == 'fuck'),'Possibly_sensitive'] = 'True'\n",
        "df.loc[(df['Content'] != 'sex')&(df['Content'] != 'rape')&(df['Content'] != 'sexual')&(df['Content'] != 'fuck'),'Possibly_sensitive'] = 'False'\n",
        "\n",
        "print(df)\n",
        "\n",
        "#Filtre sur les contenus considérés comme sensibles\n",
        "filter_df = df[df.Possibly_sensitive == 'True']\n",
        "\n",
        "print(filter_df)\n",
        "\n",
        "\n",
        "#Sensitive_content = df[df['Possibly sensitive']== True]\n",
        "\n"
      ],
      "metadata": {
        "id": "ultwc2NXo5h-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}